{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AMLS final project (Keras).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5TNNDZ5oTSr6","colab_type":"text"},"source":["# AMLS final project"]},{"cell_type":"markdown","metadata":{"id":"p8H9zARITZbY","colab_type":"text"},"source":["This notebook contains the work for the ELEC0134 Applied Machine Learning Systems class at UCL. The solution is implemented in Keras."]},{"cell_type":"markdown","metadata":{"id":"B6hARGtITkTL","colab_type":"text"},"source":["## Using Drive with Colab, typical imports"]},{"cell_type":"code","metadata":{"id":"k7gkGqqbwDxB","colab_type":"code","outputId":"70895dc5-456f-481f-faf2-8a065b274741","executionInfo":{"status":"ok","timestamp":1578181836450,"user_tz":0,"elapsed":1093,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Set up Google Drive for use with Colaboratory\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"da_PZ4Tr1D22","colab_type":"code","outputId":"e332b2f7-56ca-4c2a-fca0-452c23e94a6b","executionInfo":{"status":"ok","timestamp":1578181838806,"user_tz":0,"elapsed":781,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Import required libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","\n","# Magic calls TensorFlow 2.0 when importing\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","# This tests whether a GPU is running\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","# Import Keras\n","from tensorflow import keras\n","\n","# Check version of TensorFlow and Keras\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","2.1.0-rc1\n","2.2.4-tf\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bL2vxxQbUI7a","colab_type":"text"},"source":["## Utilities"]},{"cell_type":"code","metadata":{"id":"SR4jzONMmFxL","colab_type":"code","colab":{}},"source":["# Convert gender test generator into numpy arrays\n","# https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array\n","itr = gender_test_gen\n","gender_X_test, gender_y_test = itr.next()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fntMIGKaBRu9","colab_type":"code","colab":{}},"source":["# We check the average dimensions of the images in the dataset\n","\n","# Code from\n","# https://towardsdatascience.com/image-classification-python-keras-tutorial-kaggle-challenge-45a6332a58b8\n","\n","from PIL import Image\n","\n","def get_size_statistics(DIR, number_of_files):\n","  heights = []\n","  widths = []\n","  counter = 1\n","  for img in os.listdir(DIR):\n","    path = os.path.join(DIR, img)\n","    print(\"Opening \" + path + \": \" + str(counter) + \"/\" + str(number_of_files))\n","    data = np.array(Image.open(path)) # PIL Image library\n","    heights.append(data.shape[0])\n","    widths.append(data.shape[1])\n","    counter += 1\n","  avg_height = sum(heights) / len(heights)\n","  avg_width = sum(widths) / len(widths)\n","  print('\\n')\n","  print(\"Average Height: \" + str(avg_height))\n","  print(\"Max Height: \" + str(max(heights)))\n","  print(\"Min Height: \" + str(min(heights)))\n","  print('\\n')\n","  print(\"Average Width: \" + str(avg_width))\n","  print(\"Max Width: \" + str(max(widths)))\n","  print(\"Min Width: \" + str(min(widths)))\n","\n","get_size_statistics(\"img/\", len(df))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkZuJYdt9ijR","colab_type":"text"},"source":["##Â Creating data input pipeline"]},{"cell_type":"markdown","metadata":{"id":"v8PHkvS-gvem","colab_type":"text"},"source":["### A1, A2"]},{"cell_type":"code","metadata":{"id":"5GbNF8bYR1hu","colab_type":"code","colab":{}},"source":["root_dir = \"/content/drive/My Drive/\"\n","change_dir = root_dir + \"dataset_AMLS_19-20/celeba\"\n","\n","os.chdir(change_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yf0aPWGJS8L6","colab_type":"code","outputId":"c4e64b81-4339-453f-8c17-a73023b6a752","executionInfo":{"status":"ok","timestamp":1578181862107,"user_tz":0,"elapsed":5643,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Check current directory location and contents\n","!pwd\n","!ls"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/dataset_AMLS_19-20/celeba\n","img  labels.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E3_Hnpxu7rQR","colab_type":"code","colab":{}},"source":["# Import celeba data as dataframe, drop unnecessary column\n","df = pd.read_csv(\"labels.csv\", sep=\"\\t\", dtype=str)\n","\n","# Create separate dataframes for gender and smiling\n","gender = df.copy()\n","smiling = df.copy()\n","\n","gender.drop(gender.columns[0], axis=1, inplace=True)\n","gender.drop(gender.columns[2], axis=1, inplace=True)\n","\n","smiling.drop(smiling.columns[0], axis=1, inplace=True)\n","smiling.drop(smiling.columns[1], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yfhDyV_OgeX2","colab_type":"code","outputId":"e146419f-df1c-4ebd-dc61-512d892daad4","executionInfo":{"status":"ok","timestamp":1578181862112,"user_tz":0,"elapsed":5356,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["df.head()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>img_name</th>\n","      <th>gender</th>\n","      <th>smiling</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.jpg</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1.jpg</td>\n","      <td>-1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2.jpg</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3.jpg</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4.jpg</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Unnamed: 0 img_name gender smiling\n","0          0    0.jpg     -1       1\n","1          1    1.jpg     -1       1\n","2          2    2.jpg      1      -1\n","3          3    3.jpg     -1      -1\n","4          4    4.jpg     -1      -1"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"9ixW1Ir8ggAx","colab_type":"code","outputId":"89cde672-2faa-4581-9778-33f1b6f8c3b1","executionInfo":{"status":"ok","timestamp":1578181868510,"user_tz":0,"elapsed":1931,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["gender.head()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  img_name gender\n","0    0.jpg     -1\n","1    1.jpg     -1\n","2    2.jpg      1\n","3    3.jpg     -1\n","4    4.jpg     -1"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"aBFmtDYagh58","colab_type":"code","outputId":"0127c89f-8bea-443a-f91c-f8a0768b6f51","executionInfo":{"status":"ok","timestamp":1578181868899,"user_tz":0,"elapsed":1364,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["smiling.head()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>smiling</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  img_name smiling\n","0    0.jpg       1\n","1    1.jpg       1\n","2    2.jpg      -1\n","3    3.jpg      -1\n","4    4.jpg      -1"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"fMmnUDwy9x07","colab_type":"code","colab":{}},"source":["# Now, we create training and test sets for the gender and smiling datasets\n","from sklearn.model_selection import train_test_split\n","\n","gender_train, gender_test = train_test_split(\n","    gender, \n","    test_size=0.2,\n","    random_state=42\n","    )\n","\n","smiling_train, smiling_test = train_test_split(\n","    smiling, \n","    test_size=0.2, \n","    random_state=42\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSx1JD74__MC","colab_type":"code","outputId":"f4bfe18c-44ad-4767-b4ce-657a5f40faab","executionInfo":{"status":"ok","timestamp":1578181868906,"user_tz":0,"elapsed":950,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["gender_train.head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4227</th>\n","      <td>4227.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4676</th>\n","      <td>4676.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>800</th>\n","      <td>800.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3671</th>\n","      <td>3671.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>4193</th>\n","      <td>4193.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      img_name gender\n","4227  4227.jpg     -1\n","4676  4676.jpg      1\n","800    800.jpg      1\n","3671  3671.jpg     -1\n","4193  4193.jpg     -1"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"GKG7CrKEhjSO","colab_type":"code","outputId":"dbadea90-7541-4849-9162-de157071318b","executionInfo":{"status":"ok","timestamp":1578181868909,"user_tz":0,"elapsed":858,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(gender_train))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["4000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KSBBc9ffhW5c","colab_type":"code","outputId":"87fceb15-fe2f-459b-f0bc-659c338bdaef","executionInfo":{"status":"ok","timestamp":1578181870862,"user_tz":0,"elapsed":1810,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["gender_test.head()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1501</th>\n","      <td>1501.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2586</th>\n","      <td>2586.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2653</th>\n","      <td>2653.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>1055</th>\n","      <td>1055.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>705</th>\n","      <td>705.jpg</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      img_name gender\n","1501  1501.jpg     -1\n","2586  2586.jpg     -1\n","2653  2653.jpg     -1\n","1055  1055.jpg     -1\n","705    705.jpg      1"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"KAJ031oQhkw7","colab_type":"code","outputId":"8c5cdc14-ea12-4881-8aa3-008b30462101","executionInfo":{"status":"ok","timestamp":1578181870864,"user_tz":0,"elapsed":1301,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(gender_test))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EN_UtDuWhoqh","colab_type":"code","outputId":"de7ecc7c-7318-45fa-c1ab-6aac98784499","executionInfo":{"status":"ok","timestamp":1578181870866,"user_tz":0,"elapsed":915,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["smiling_train.head()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>smiling</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4227</th>\n","      <td>4227.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4676</th>\n","      <td>4676.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>800</th>\n","      <td>800.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>3671</th>\n","      <td>3671.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4193</th>\n","      <td>4193.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      img_name smiling\n","4227  4227.jpg       1\n","4676  4676.jpg       1\n","800    800.jpg      -1\n","3671  3671.jpg       1\n","4193  4193.jpg      -1"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"PTTQKgUths_7","colab_type":"code","outputId":"2a413200-6f0d-4127-c47d-0d6e6173b577","executionInfo":{"status":"ok","timestamp":1578181871334,"user_tz":0,"elapsed":826,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(smiling_train))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["4000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GlyT7X1zhuvE","colab_type":"code","outputId":"08be565f-963e-4bb9-a2d2-dafb7307ac2c","executionInfo":{"status":"ok","timestamp":1578181871642,"user_tz":0,"elapsed":854,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["smiling_test.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_name</th>\n","      <th>smiling</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1501</th>\n","      <td>1501.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2586</th>\n","      <td>2586.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2653</th>\n","      <td>2653.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1055</th>\n","      <td>1055.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>705</th>\n","      <td>705.jpg</td>\n","      <td>-1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      img_name smiling\n","1501  1501.jpg       1\n","2586  2586.jpg       1\n","2653  2653.jpg       1\n","1055  1055.jpg       1\n","705    705.jpg      -1"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"eNFEsbCVhwx0","colab_type":"code","outputId":"9663b47d-125b-41f4-dfc4-c3dab01a860b","executionInfo":{"status":"ok","timestamp":1578181871941,"user_tz":0,"elapsed":670,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(smiling_test))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8twoTv_ZVDy7","colab_type":"code","outputId":"b9a394d5-0e12-4e0d-94a4-9752afb4ee78","executionInfo":{"status":"ok","timestamp":1578181878207,"user_tz":0,"elapsed":5498,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# We now create two ImageDataGenerator objects for the gender dataset:\n","# one for training, the other for validation\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# https://forums.fast.ai/t/split-data-using-fit-generator/4380/4\n","# for validation split\n","\n","# We rescale to ensure RGB values fall between 0 and 1\n","# We set aside 20% of the training set for validation\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","# We generate an image-label pair for the training set as follows\n","gender_train_gen = datagen.flow_from_dataframe(\n","    dataframe=gender_train, \n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"gender\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=32,\n","    subset=\"training\"\n","    )\n","\n","# We generate an image-label pair for the validation set as follows\n","gender_val_gen = datagen.flow_from_dataframe(\n","    dataframe=gender_train, \n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"gender\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=32,\n","    subset=\"validation\"\n","    )\n","\n","# We generate an image-label pair for the gender test set as follows\n","# We set batch_size = size of test set\n","gender_test_gen = datagen.flow_from_dataframe(\n","    dataframe=gender_test, \n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"gender\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=len(gender_test)\n","    )"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Found 3200 validated image filenames belonging to 2 classes.\n","Found 800 validated image filenames belonging to 2 classes.\n","Found 1000 validated image filenames belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kr6gb9fH6lJ3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7L01fNRJwp9b","colab_type":"code","cellView":"code","outputId":"351da356-c59b-48e4-e3ba-e1d0b12d1930","executionInfo":{"status":"ok","timestamp":1578162293196,"user_tz":0,"elapsed":21472,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["# Create two ImageDataGenerator objects for the smiling dataset in a similar way\n","\n","# https://forums.fast.ai/t/split-data-using-fit-generator/4380/4\n","# for validation split\n","\n","# We rescale to ensure RGB values fall between 0 and 1\n","# We set aside 20% of the training set for validation\n","datagen = ImageDataGenerator(rescale=1./255,\n","                             validation_split=0.2)\n","\n","# We generate an image-label pair for the training set as follows\n","smiling_train_gen = datagen.flow_from_dataframe(\n","    dataframe=smiling_train,\n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"smiling\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=32,\n","    subset=\"training\"\n","    )\n","\n","# We generate an image-label pair for the validation set as follows\n","smiling_val_gen = datagen.flow_from_dataframe(\n","    dataframe=smiling_train,\n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"smiling\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=32,\n","    subset=\"validation\"\n","    )\n","\n","# We generate an image-label pair for the gender test set as follows\n","# We set batch_size = size of test set\n","smiling_test_gen = datagen.flow_from_dataframe(\n","    dataframe=smiling_test, \n","    directory=\"img/\",\n","    x_col=\"img_name\",\n","    y_col=\"smiling\",\n","    class_mode=\"sparse\",\n","    target_size=(218,178),\n","    batch_size=len(smiling_test)\n","    )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 3200 validated image filenames belonging to 2 classes.\n","Found 800 validated image filenames belonging to 2 classes.\n","Found 1000 validated image filenames belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mG-WVawtjzCN"},"source":["### B1, B2"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"of9GUTVHjzCW","colab":{}},"source":["root_dir = \"/content/drive/My Drive/\"\n","change_dir = root_dir + \"dataset_AMLS_19-20/cartoon_set\"\n","\n","os.chdir(change_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"84433009-925d-4a32-ec5e-12aeda7d9224","executionInfo":{"status":"ok","timestamp":1578163978372,"user_tz":0,"elapsed":3250,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"eCZz3_PNjzCi","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Check current directory location and contents\n","!pwd\n","!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/dataset_AMLS_19-20/cartoon_set\n","img  labels.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2TgTmO21jzCs","colab":{}},"source":["# Import celeba data as dataframe, drop unnecessary column\n","df = pd.read_csv(\"labels.csv\", sep=\"\\t\", dtype=str)\n","\n","# Create separate dataframes for face shape and eye color\n","face_shape = df.copy()\n","eye_color = df.copy()\n","\n","face_shape.drop(face_shape.columns[0], axis=1, inplace=True)\n","face_shape.drop(face_shape.columns[0], axis=1, inplace=True)\n","\n","eye_color.drop(eye_color.columns[0], axis=1, inplace=True)\n","eye_color.drop(eye_color.columns[1], axis=1, inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"db94f86a-fd68-49d6-8322-ae2a456d98ce","executionInfo":{"status":"ok","timestamp":1578163981531,"user_tz":0,"elapsed":467,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"zeBOiuyAjzC0","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>eye_color</th>\n","      <th>face_shape</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>1.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>4.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Unnamed: 0 eye_color face_shape file_name\n","0          0         1          4     0.png\n","1          1         2          4     1.png\n","2          2         2          3     2.png\n","3          3         2          0     3.png\n","4          4         0          2     4.png"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a5ae0c75-abeb-484c-a398-9df26f4fb0e9","executionInfo":{"status":"ok","timestamp":1578163982582,"user_tz":0,"elapsed":432,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"fjz8xTM1jzC7","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["face_shape.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>face_shape</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>0.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>1.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>2.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>4.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  face_shape file_name\n","0          4     0.png\n","1          4     1.png\n","2          3     2.png\n","3          0     3.png\n","4          2     4.png"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"91644cba-bef4-45ca-add8-94e3ef6bf3e0","executionInfo":{"status":"ok","timestamp":1578163983547,"user_tz":0,"elapsed":501,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"zADp2vdOjzDD","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["eye_color.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eye_color</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>3.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  eye_color file_name\n","0         1     0.png\n","1         2     1.png\n","2         2     2.png\n","3         2     3.png\n","4         0     4.png"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KgxRXKBWjzDJ","colab":{}},"source":["# Now, we create training and test sets for the face shape and eye color datasets\n","face_shape_train, face_shape_test = train_test_split(\n","    face_shape, \n","    test_size=0.2,\n","    random_state=42\n","    )\n","\n","eye_color_train, eye_color_test = train_test_split(\n","    eye_color, \n","    test_size=0.2, \n","    random_state=42\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"8432f958-d91d-4f5c-b566-63ee5a61447c","executionInfo":{"status":"ok","timestamp":1578163985456,"user_tz":0,"elapsed":451,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"On6nPOzxjzDf","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["face_shape_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>face_shape</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9254</th>\n","      <td>2</td>\n","      <td>9254.png</td>\n","    </tr>\n","    <tr>\n","      <th>1561</th>\n","      <td>1</td>\n","      <td>1561.png</td>\n","    </tr>\n","    <tr>\n","      <th>1670</th>\n","      <td>1</td>\n","      <td>1670.png</td>\n","    </tr>\n","    <tr>\n","      <th>6087</th>\n","      <td>2</td>\n","      <td>6087.png</td>\n","    </tr>\n","    <tr>\n","      <th>6669</th>\n","      <td>2</td>\n","      <td>6669.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     face_shape file_name\n","9254          2  9254.png\n","1561          1  1561.png\n","1670          1  1670.png\n","6087          2  6087.png\n","6669          2  6669.png"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b72dc09f-e884-4070-e854-167526f543f1","executionInfo":{"status":"ok","timestamp":1578163986701,"user_tz":0,"elapsed":832,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"qSpIpxa6jzDm","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(face_shape_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["8000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5535f338-0ef3-461b-c5e0-777e0ede7206","executionInfo":{"status":"ok","timestamp":1578163986902,"user_tz":0,"elapsed":586,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"ga2a2B4TjzDt","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["face_shape_test.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>face_shape</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6252</th>\n","      <td>3</td>\n","      <td>6252.png</td>\n","    </tr>\n","    <tr>\n","      <th>4684</th>\n","      <td>0</td>\n","      <td>4684.png</td>\n","    </tr>\n","    <tr>\n","      <th>1731</th>\n","      <td>0</td>\n","      <td>1731.png</td>\n","    </tr>\n","    <tr>\n","      <th>4742</th>\n","      <td>1</td>\n","      <td>4742.png</td>\n","    </tr>\n","    <tr>\n","      <th>4521</th>\n","      <td>1</td>\n","      <td>4521.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     face_shape file_name\n","6252          3  6252.png\n","4684          0  4684.png\n","1731          0  1731.png\n","4742          1  4742.png\n","4521          1  4521.png"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ebd426c3-c280-4a3e-e7d8-abb295ecc8fa","executionInfo":{"status":"ok","timestamp":1578163987897,"user_tz":0,"elapsed":719,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"1EgOjJq0jzDz","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(face_shape_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e51aeb3e-0f8b-4d79-fe5a-50f0b0de1f60","executionInfo":{"status":"ok","timestamp":1578163988192,"user_tz":0,"elapsed":363,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"KXh__EOcjzD5","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["eye_color_train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eye_color</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9254</th>\n","      <td>0</td>\n","      <td>9254.png</td>\n","    </tr>\n","    <tr>\n","      <th>1561</th>\n","      <td>2</td>\n","      <td>1561.png</td>\n","    </tr>\n","    <tr>\n","      <th>1670</th>\n","      <td>3</td>\n","      <td>1670.png</td>\n","    </tr>\n","    <tr>\n","      <th>6087</th>\n","      <td>2</td>\n","      <td>6087.png</td>\n","    </tr>\n","    <tr>\n","      <th>6669</th>\n","      <td>3</td>\n","      <td>6669.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     eye_color file_name\n","9254         0  9254.png\n","1561         2  1561.png\n","1670         3  1670.png\n","6087         2  6087.png\n","6669         3  6669.png"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0f24d83a-bd24-4767-f392-6d83a761c238","executionInfo":{"status":"ok","timestamp":1578163988843,"user_tz":0,"elapsed":408,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"-1OFkhxOjzD_","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(eye_color_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["8000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a9ff0d35-c3fc-457d-9d2b-8b863b511ba5","executionInfo":{"status":"ok","timestamp":1578163989513,"user_tz":0,"elapsed":490,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"DhKY7-RejzEF","colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["eye_color_test.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eye_color</th>\n","      <th>file_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6252</th>\n","      <td>2</td>\n","      <td>6252.png</td>\n","    </tr>\n","    <tr>\n","      <th>4684</th>\n","      <td>2</td>\n","      <td>4684.png</td>\n","    </tr>\n","    <tr>\n","      <th>1731</th>\n","      <td>4</td>\n","      <td>1731.png</td>\n","    </tr>\n","    <tr>\n","      <th>4742</th>\n","      <td>2</td>\n","      <td>4742.png</td>\n","    </tr>\n","    <tr>\n","      <th>4521</th>\n","      <td>1</td>\n","      <td>4521.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     eye_color file_name\n","6252         2  6252.png\n","4684         2  4684.png\n","1731         4  1731.png\n","4742         2  4742.png\n","4521         1  4521.png"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"df9137b9-86b0-407d-9eec-b64c7b62297e","executionInfo":{"status":"ok","timestamp":1578163990279,"user_tz":0,"elapsed":552,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"bjAcZgQmjzEK","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(eye_color_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"efe956e1-d797-4815-d00e-263975dacbab","executionInfo":{"status":"ok","timestamp":1578164040587,"user_tz":0,"elapsed":49985,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"O7LnF_GEjzEQ","colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["# We now create two ImageDataGenerator objects for the face shape dataset:\n","# one for training, the other for validation\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# https://forums.fast.ai/t/split-data-using-fit-generator/4380/4\n","# for validation split\n","\n","# We rescale to ensure RGB values fall between 0 and 1\n","# We set aside 20% of the training set for validation\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","# We generate an image-label pair for the training set as follows\n","face_shape_train_gen = datagen.flow_from_dataframe(\n","    dataframe=face_shape_train, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"face_shape\",\n","    class_mode=\"sparse\",\n","    target_size=(500,500),\n","    batch_size=32,\n","    subset=\"training\"\n","    )\n","\n","# We generate an image-label pair for the validation set as follows\n","face_shape_val_gen = datagen.flow_from_dataframe(\n","    dataframe=face_shape_train, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"face_shape\",\n","    class_mode=\"sparse\",\n","    target_size=(500,500),\n","    batch_size=32,\n","    subset=\"validation\"\n","    )\n","\n","# We generate an image-label pair for the gender test set as follows\n","# We set batch_size = size of test set\n","face_shape_test_gen = datagen.flow_from_dataframe(\n","    dataframe=face_shape_test, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"face_shape\",\n","    class_mode=\"sparse\",\n","    target_size=(500,500),\n","    batch_size=len(face_shape_test)\n","    )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 14 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"},{"output_type":"stream","text":["Found 6389 validated image filenames belonging to 5 classes.\n","Found 1597 validated image filenames belonging to 5 classes.\n","Found 1996 validated image filenames belonging to 5 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","cellView":"code","outputId":"81663a45-78f1-499e-8a39-90323ef97da0","executionInfo":{"status":"ok","timestamp":1578164066414,"user_tz":0,"elapsed":12530,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"id":"lmkFnyH7jzEW","colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["# Create two ImageDataGenerator objects for the eye color dataset in a similar way\n","\n","# https://forums.fast.ai/t/split-data-using-fit-generator/4380/4\n","# for validation split\n","\n","# We rescale to ensure RGB values fall between 0 and 1\n","# We set aside 20% of the training set for validation\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","# We generate an image-label pair for the training set as follows\n","eye_color_train_gen = datagen.flow_from_dataframe(\n","    dataframe=eye_color_train, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"eye_color\",\n","    class_mode=\"sparse\",\n","    target_size=(250,250),\n","    batch_size=32,\n","    subset=\"training\"\n","    )\n","\n","# We generate an image-label pair for the validation set as follows\n","eye_color_val_gen = datagen.flow_from_dataframe(\n","    dataframe=eye_color_train, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"eye_color\",\n","    class_mode=\"sparse\",\n","    target_size=(250,250),\n","    batch_size=32,\n","    subset=\"validation\"\n","    )\n","\n","# We generate an image-label pair for the gender test set as follows\n","# We set batch_size = size of test set\n","eye_color_test_gen = datagen.flow_from_dataframe(\n","    dataframe=eye_color_test, \n","    directory=\"img/\",\n","    x_col=\"file_name\",\n","    y_col=\"eye_color\",\n","    class_mode=\"sparse\",\n","    target_size=(250,250),\n","    batch_size=len(eye_color_test)\n","    )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 14 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"},{"output_type":"stream","text":["Found 6389 validated image filenames belonging to 5 classes.\n","Found 1597 validated image filenames belonging to 5 classes.\n","Found 1996 validated image filenames belonging to 5 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/tensorflow-2.1.0/python3.6/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"file_name\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wr0FwWDqZ7r2","colab_type":"text"},"source":["## Building and training the models\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mQHoFG_p1iQk","colab_type":"text"},"source":["### Multi-layer Perceptron (MLP)"]},{"cell_type":"code","metadata":{"id":"1Y8QKi8JC_P6","colab_type":"code","colab":{}},"source":["# Creating a classification MLP with two hidden layers\n","# We are using the Sequential API which creates a stack of layers\n","# in which the input flows through one after the other\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# Instantiate Sequential API\n","mlp_model = keras.models.Sequential()\n","\n","# This flattens the 218x178x3 input into a 1D tensor\n","mlp_model.add(keras.layers.Flatten(input_shape=(218,178,3)))\n","\n","# This adds a fully connected layer with 300 neurons using the ReLU\n","# activation function\n","mlp_model.add(keras.layers.Dense(300, activation=\"relu\"))\n","\n","# This adds a fully connected layer with 100 neurons using the ReLU\n","# activation function\n","mlp_model.add(keras.layers.Dense(100, activation=\"relu\"))\n","\n","# This creates the output layer.\n","mlp_model.add(keras.layers.Dense(5, activation=\"softmax\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoRYa4hQEBQv","colab_type":"code","colab":{}},"source":["# We now compile the MLP model to specify the loss function\n","# and the optimizer to use (SGD)\n","\n","mlp_model.compile(loss=\"sparse_categorical_crossentropy\", # b/c of exclusive, sparse outputs\n","                  optimizer='sgd', # We use SGD to optimise the ANN\n","                  metrics=[\"accuracy\"] # Used for classifiers\n","                  ) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPy7Oq5e2q8a","colab_type":"code","outputId":"3604130f-5476-49d8-9648-4eb779840171","executionInfo":{"status":"ok","timestamp":1578179946194,"user_tz":0,"elapsed":863,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(gender_train_gen.samples)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"km8sD1CyEM-K","colab_type":"code","outputId":"bfa87794-3e08-4404-d071-590a71710bf7","executionInfo":{"status":"ok","timestamp":1578183825257,"user_tz":0,"elapsed":1907963,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":243}},"source":["# Training and evaluating the MLP model on the gender dataset\n","gender_history = mlp_model.fit(\n","    gender_train_gen,\n","    steps_per_epoch=gender_train_gen.samples // 32,\n","    validation_data=gender_val_gen,\n","    validation_steps=gender_val_gen.samples // 32,\n","    epochs=2\n","    )"],"execution_count":40,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 100 steps, validate for 25 steps\n","Epoch 1/2\n","100/100 [==============================] - 1866s 19s/step - loss: 0.9648 - accuracy: 0.5400 - val_loss: 0.6951 - val_accuracy: 0.5575\n","Epoch 2/2\n","100/100 [==============================] - 10s 102ms/step - loss: 0.6540 - accuracy: 0.6484 - val_loss: 0.6522 - val_accuracy: 0.7138\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OfFCHY6pPzbc","colab_type":"code","outputId":"756805b2-4f6f-4473-a188-13fb2f4fe4f9","executionInfo":{"status":"ok","timestamp":1578185331622,"user_tz":0,"elapsed":711,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["gender_history.history.get('val_accuracy')[-1]"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.71375"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"5HxmbOxCXZgD","colab_type":"code","outputId":"01134430-e63d-4a8d-8053-26867b97c62e","executionInfo":{"status":"error","timestamp":1578184965455,"user_tz":0,"elapsed":12552,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":311}},"source":["mlp_model.evaluate(gender_test_gen)"],"execution_count":47,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-855a0d052c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_test_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m   def predict(self,\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    954\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"avIUzrJDtJRV","colab_type":"code","colab":{}},"source":["# Training and evaluating the MLP model on the gender dataset\n","smiling_history = mlp_model.fit(\n","    smiling_train_gen,\n","    steps_per_epoch=smiling_train_gen.samples // 32,\n","    validation_data=smiling_val_gen,\n","    validation_steps=smiling_val_gen.samples // 32,\n","    epochs=10\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNDU_C5zZ0w1","colab_type":"code","outputId":"9e3008e6-4c0a-4f38-fd1c-3db9cecc91de","executionInfo":{"status":"error","timestamp":1578184864485,"user_tz":0,"elapsed":3375,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":398}},"source":["# Convert gender test generator into numpy arrays\n","# https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array\n","def get_X_y_test_sets(test_gen):\n","    itr = gender_test_gen\n","    print(\"Splitting ImageDataGenerator. This may take a while...\")\n","    gender_X_test, gender_y_test = itr.next()\n","    print(\"Splitting complete.\")\n","    return gender_X_test, gender_y_test\n","\n","# Get indices of wrongfully misclassified test set\n","# https://stackoverflow.com/questions/39300880/how-to-find-wrong-prediction-cases-in-test-set-cnns-using-keras\n","def get_wrong_indices(X_test, y_test):\n","    incorrects = np.asarray(np.nonzero(cnn_model.predict(X_test).argmax(axis=-1).reshape((-1,)) != y_test))\n","    incorrects = incorrects.T.flatten()\n","    return incorrects\n","\n","# This returns an array which contains the predictions for the misclassified images\n","def get_incorrect_preds(X_test, y_test, incorrects):\n","    incorrect_preds = []\n","\n","    for incorrect in np.nditer(incorrects):\n","        probs_pred = cnn_model.predict(gender_X_test[incorrect:incorrect+1])\n","        incorrect_pred = probs_pred.argmax(axis=-1)\n","        incorrect_preds.append(incorrect_pred)\n","\n","    incorrect_preds = np.asarray(incorrect_preds)\n","    incorrect_preds = incorrect_preds.T.flatten()\n","    incorrect_preds = incorrect_preds.astype(float)\n","    return incorrect_preds\n","\n","# This returns an array which contains the actual labels for the misclassified images\n","def get_actual_labels(X_test, y_test, incorrects):\n","    actual_labels = []\n","\n","    for incorrect in np.nditer(incorrects):\n","        actual_label = y_test[incorrect]\n","        actual_labels.append(actual_label)\n","\n","    actual_labels = np.asarray(actual_labels)\n","    actual_labels = actual_labels.T.flatten()\n","    actual_labels = actual_labels.astype(float)\n","    return actual_labels\n","\n","# This returns an array which contains the individual losses for the misclassified images\n","def get_incorrect_losses(X_test, y_test, incorrects):\n","    incorrect_losses = [] \n","\n","    for incorrect in np.nditer(incorrects):\n","        loss = cnn_model.evaluate(X_test[incorrect:incorrect+1], y_test[incorrect:incorrect+1], verbose=0)\n","        incorrect_losses.append(loss[0])\n","\n","    incorrect_losses = np.asarray(incorrect_losses)\n","    incorrect_losses = incorrect_losses.astype(float)\n","    return incorrect_losses\n","\n","def get_probs_correct_label(X_test, y_test, incorrects):\n","# This returns an array which contains the probabilities of the actual label\n","# for the misclassified images\n","    probs_correct_label = []\n","\n","    for incorrect in np.nditer(incorrects):\n","        prob_correct_label = cnn_model.predict(gender_X_test[incorrect:incorrect+1])\n","        probs_correct_label.append(prob_correct_label[0,int(gender_y_test[incorrect])])\n","\n","    probs_correct_label = np.asarray(probs_correct_label)\n","    probs_correct_label = probs_correct_label.astype(float)\n","    return probs_correct_label\n","\n","def create_loss_pred_data(X_test, y_test):\n","    incorrects = get_wrong_indices(X_test, y_test)\n","    incorrect_preds = get_incorrect_preds(X_test, y_test, incorrects)\n","    actual_labels = get_actual_labels(X_test, y_test, incorrects)\n","    incorrect_losses = get_incorrect_losses(X_test, y_test, incorrects)\n","    probs_correct_label = get_probs_correct_label(X_test, y_test, incorrects)\n","\n","    # This joins together the indices of incorrectly misclassified images, their losses and\n","    # actual label probabilities into a numpy array. It is then sorted in descending order\n","    loss_pred_data = np.column_stack((incorrects.astype(float), \n","                                      incorrect_preds, \n","                                      actual_labels, \n","                                      incorrect_losses, \n","                                      probs_correct_label))\n","    loss_pred_data = loss_pred_data[np.argsort(loss_pred_data[:,3])[::-1]]\n","    return loss_pred_data\n","\n","# This plots a single misclassified image alongside its predicted label,\n","# its actual label, the error rate for the image and the probability given\n","# to the actual label\n","def plot_image(i, loss_pred_data, img_data):\n","    plt.imshow(img_data[int(loss_pred_data[i,0])])\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.xlabel(\"{}/{} {:0.2f} {:0.2f}\".format(int(loss_pred_data[i,1]),\n","                                              int(loss_pred_data[i,2]),\n","                                              loss_pred_data[i,3],\n","                                              loss_pred_data[i,4]))\n","\n","# This plots the images which have been the most misclassified when running the\n","# model on the test set. Inspired by the plot_top_losses function in the fastai\n","# library\n","def plot_top_losses(X_test, y_test, num_rows, num_cols):\n","    loss_pred_data = create_loss_pred_data(gender_X_test, gender_y_test)\n","    num_images = num_rows*num_cols\n","    plt.figure(figsize=(2*num_cols, 2*num_rows))\n","    for i in range(num_images):\n","        plt.subplot(num_rows, num_cols, i+1)\n","        plot_image(i, loss_pred_data, X_test)\n","    plt.tight_layout()\n","    return plt.show()\n","\n","gender_X_test, gender_y_test = get_X_y_test_sets(gender_test_gen)\n","\n","plot_top_losses(gender_X_test, gender_y_test, 3, 3)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Splitting ImageDataGenerator. This may take a while...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-dca469ba99e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mgender_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_y_test_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_test_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mplot_top_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-dca469ba99e9>\u001b[0m in \u001b[0;36mget_X_y_test_sets\u001b[0;34m(test_gen)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mitr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgender_test_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Splitting ImageDataGenerator. This may take a while...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgender_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Splitting complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgender_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.1.0/python3.6/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"zPeNAub7rq5T","colab_type":"code","colab":{}},"source":["# Training and evaluating the MLP model on the smiling dataset\n","mlp_smiling_history = mlp_model.fit(\n","    smiling_train_gen,\n","    steps_per_epoch=smiling_train_gen.samples // 32,\n","    validation_data=smiling_val_gen,\n","    validation_steps=smiling_val_gen.samples // 32,\n","    epochs=30\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7Y82fybcrx8","colab_type":"code","outputId":"c3bf81d9-82e5-4b82-bb7c-7138f02ca718","executionInfo":{"status":"ok","timestamp":1578055878792,"user_tz":0,"elapsed":450,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["get_wrong_indices(gender_X_test, gender_y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([], dtype=int64)"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"r2NcqFgLN5Ne","colab_type":"text"},"source":["### ResNet50"]},{"cell_type":"code","metadata":{"id":"a1vXx6d8N7Di","colab_type":"code","outputId":"0c449192-9f35-4e94-8b49-69130ea44d6e","executionInfo":{"status":"ok","timestamp":1578156600096,"user_tz":0,"elapsed":7007,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["base_model = keras.applications.resnet_v2.ResNet50V2(weights=\"imagenet\",\n","                                                     include_top=False,\n","                                                     input_shape=(500, 500, 3))\n","avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n","output = keras.layers.Dense(5, activation=\"softmax\")(avg)\n","resnet50v2_model = keras.Model(inputs=base_model.input, outputs=output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94674944/94668760 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sp59bwbBRppa","colab_type":"code","colab":{}},"source":["for layer in base_model.layers:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6qwgb5PR0Ev","colab_type":"code","outputId":"a5b5c2c8-5d55-4916-dbe9-0ef0c6fde451","executionInfo":{"status":"ok","timestamp":1578157006756,"user_tz":0,"elapsed":378223,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n","\n","resnet50v2_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","resnet50v2history = resnet50v2_model.fit(eye_color_train_gen, epochs=5, validation_data=eye_color_val_gen)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 200 steps, validate for 50 steps\n","Epoch 1/5\n","200/200 [==============================] - 79s 395ms/step - loss: 5.6075 - accuracy: 0.4376 - val_loss: 6.8243 - val_accuracy: 0.2248\n","Epoch 2/5\n","200/200 [==============================] - 74s 372ms/step - loss: 1.7246 - accuracy: 0.5934 - val_loss: 3.2253 - val_accuracy: 0.2905\n","Epoch 3/5\n","200/200 [==============================] - 74s 372ms/step - loss: 1.0661 - accuracy: 0.6652 - val_loss: 3.2229 - val_accuracy: 0.2837\n","Epoch 4/5\n","200/200 [==============================] - 74s 371ms/step - loss: 0.9344 - accuracy: 0.6840 - val_loss: 3.1006 - val_accuracy: 0.2918\n","Epoch 5/5\n","200/200 [==============================] - 75s 374ms/step - loss: 0.8265 - accuracy: 0.7007 - val_loss: 3.1270 - val_accuracy: 0.2899\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ARRXLJi1mIH","colab_type":"text"},"source":["### Convolutional Neural Network (CNN)"]},{"cell_type":"code","metadata":{"id":"1UWw3A3QS9Ig","colab_type":"code","colab":{}},"source":["# We create a simple CNN architecture for image classification\n","# Architecture from:\n","# https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb#scrollTo=L1WtoaOHVrVh\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n","\n","cnn_model = Sequential([\n","    Conv2D(16, 3, padding='same', activation='relu', input_shape=(218,178,3)),\n","    MaxPooling2D(),\n","    Conv2D(32, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Conv2D(64, 3, padding='same', activation='relu'),\n","    MaxPooling2D(),\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dense(2, activation='softmax')\n","    ])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ngo25rrhSwVe","colab_type":"code","colab":{}},"source":["# We now compile the CNN model to specify the loss function\n","# and the optimizer to use (Adam)\n","cnn_model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5QAbsFpUljW","colab_type":"code","outputId":"a8a4f485-30d1-4c85-b03a-d6350c6a56df","executionInfo":{"status":"ok","timestamp":1578163902504,"user_tz":0,"elapsed":1219958,"user":{"displayName":"Raph Sedano","photoUrl":"","userId":"08972947671961729996"}},"colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["# Training and evaluating the CNN model on the gender dataset\n","cnn_gender_history = cnn_model.fit(\n","    gender_train_gen,\n","    steps_per_epoch=gender_train_gen.samples // 32,\n","    validation_data=gender_val_gen,\n","    validation_steps=gender_val_gen.samples // 32,\n","    epochs=10\n","    )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 100 steps, validate for 25 steps\n","Epoch 1/10\n","100/100 [==============================] - 1129s 11s/step - loss: 0.5223 - accuracy: 0.7519 - val_loss: 0.3748 - val_accuracy: 0.8450\n","Epoch 2/10\n","100/100 [==============================] - 10s 102ms/step - loss: 0.2401 - accuracy: 0.9038 - val_loss: 0.2674 - val_accuracy: 0.8988\n","Epoch 3/10\n","100/100 [==============================] - 10s 101ms/step - loss: 0.1672 - accuracy: 0.9359 - val_loss: 0.2755 - val_accuracy: 0.8963\n","Epoch 4/10\n","100/100 [==============================] - 10s 100ms/step - loss: 0.1061 - accuracy: 0.9600 - val_loss: 0.3034 - val_accuracy: 0.9038\n","Epoch 5/10\n","100/100 [==============================] - 10s 99ms/step - loss: 0.0587 - accuracy: 0.9812 - val_loss: 0.3039 - val_accuracy: 0.9075\n","Epoch 6/10\n","100/100 [==============================] - 10s 101ms/step - loss: 0.0478 - accuracy: 0.9816 - val_loss: 0.3701 - val_accuracy: 0.8900\n","Epoch 7/10\n","100/100 [==============================] - 10s 99ms/step - loss: 0.0628 - accuracy: 0.9753 - val_loss: 0.3588 - val_accuracy: 0.9112\n","Epoch 8/10\n","100/100 [==============================] - 10s 100ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.4255 - val_accuracy: 0.9013\n","Epoch 9/10\n","100/100 [==============================] - 10s 97ms/step - loss: 0.0100 - accuracy: 0.9959 - val_loss: 0.4936 - val_accuracy: 0.9062\n","Epoch 10/10\n","100/100 [==============================] - 10s 97ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.5375 - val_accuracy: 0.9087\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pVaz0P3J_d0b","colab_type":"text"},"source":["## Next Steps\n","\n","* Figure out the principles for building a good MLP and CNN and  architecture for image classification\n","  * Do experiment on distributing hidden layers evenly, 25/75, 75/25 split.\n","* Read chapter on training deep neural nets\n","* Figure out how to do learning rate finder and one cycle learning\n","* Do literature review\n","* Write the code in a format that works for submission"]}]}